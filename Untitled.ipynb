{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kalijauhari/research/blob/main/Untitled.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v-42o9e3CeMJ"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "torch.cuda.is_available()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YsZOpqYGCi-M"
      },
      "outputs": [],
      "source": [
        "!pip install datasets transformers huggingface_hub\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vNVD5-6CCrQ7"
      },
      "outputs": [],
      "source": [
        "!apt-get install git-lfs\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2CzvYDngCu9F"
      },
      "outputs": [],
      "source": [
        "from datasets import load_dataset\n",
        "imdb = load_dataset(\"imdb\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j60_QnsxCzIx"
      },
      "outputs": [],
      "source": [
        "small_train_dataset = imdb[\"train\"].shuffle(seed=42).select([i for i in list(range(3000))])\n",
        "small_test_dataset = imdb[\"test\"].shuffle(seed=42).select([i for i in list(range(300))])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O-jDESaLC_Jj"
      },
      "outputs": [],
      "source": [
        "from transformers import AutoTokenizer\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"distilbert-base-uncased\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iuLsZItrDB5k"
      },
      "outputs": [],
      "source": [
        "def preprocess_function(examples):\n",
        "   return tokenizer(examples[\"text\"], truncation=True)\n",
        " \n",
        "tokenized_train = small_train_dataset.map(preprocess_function, batched=True)\n",
        "tokenized_test = small_test_dataset.map(preprocess_function, batched=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B5RLUo3wDIyq"
      },
      "outputs": [],
      "source": [
        "from transformers import DataCollatorWithPadding\n",
        "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DwyVvQcEDLIL"
      },
      "outputs": [],
      "source": [
        "from transformers import AutoModelForSequenceClassification\n",
        "model = AutoModelForSequenceClassification.from_pretrained(\"distilbert-base-uncased\", num_labels=2)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vk2Sl6ysDSWa"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from datasets import load_metric\n",
        " \n",
        "def compute_metrics(eval_pred):\n",
        "   load_accuracy = load_metric(\"accuracy\")\n",
        "   load_f1 = load_metric(\"f1\")\n",
        "  \n",
        "   logits, labels = eval_pred\n",
        "   predictions = np.argmax(logits, axis=-1)\n",
        "   accuracy = load_accuracy.compute(predictions=predictions, references=labels)[\"accuracy\"]\n",
        "   f1 = load_f1.compute(predictions=predictions, references=labels)[\"f1\"]\n",
        "   return {\"accuracy\": accuracy, \"f1\": f1}\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "r5Jvq3nkDWX2"
      },
      "outputs": [],
      "source": [
        "from huggingface_hub import notebook_login\n",
        "notebook_login()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3idqEDmgD-vx"
      },
      "outputs": [],
      "source": [
        "from transformers import TrainingArguments, Trainer\n",
        " \n",
        "repo_name = \"finetuning-sentiment-model-3000-samples\"\n",
        " \n",
        "training_args = TrainingArguments(\n",
        "   output_dir=repo_name,\n",
        "   learning_rate=2e-5,\n",
        "   per_device_train_batch_size=16,\n",
        "   per_device_eval_batch_size=16,\n",
        "   num_train_epochs=2,\n",
        "   weight_decay=0.01,\n",
        "   save_strategy=\"epoch\",\n",
        "   push_to_hub=True,\n",
        ")\n",
        " \n",
        "trainer = Trainer(\n",
        "   model=model,\n",
        "   args=training_args,\n",
        "   train_dataset=tokenized_train,\n",
        "   eval_dataset=tokenized_test,\n",
        "   tokenizer=tokenizer,\n",
        "   data_collator=data_collator,\n",
        "   compute_metrics=compute_metrics,\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "gVenEKJ9EGBW",
        "outputId": "b5a706b6-9708-4a8b-e314-a1e0b2d12852"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/transformers/optimization.py:391: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n",
            "You're using a DistilBertTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='74' max='376' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [ 74/376 58:53 < 4:07:02, 0.02 it/s, Epoch 0.39/2]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "trainer.train()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "COMstO9AEKZk"
      },
      "outputs": [],
      "source": [
        "trainer.evaluate()\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNztevgSnQl+jpojnz6nqeL",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}